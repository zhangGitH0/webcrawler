{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_games(object):\n",
    "    \n",
    "    from urllib.request import Request,urlopen\n",
    "    from selenium import webdriver\n",
    "    from bs4 import BeautifulSoup\n",
    "    from datetime import datetime, timedelta\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    import random\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    head = 'https://www.walmart.com/'\n",
    "\n",
    "    chromedriver = '/Users/bozhang/Documents/Software/chromedriver'\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "    #search_key = 'nintendo+switch+games'\n",
    "\n",
    "    def get_soup(self, url): # function 1-get webpage\n",
    "        \"\"\"\n",
    "        This function get the beautifulsoup object of a webpage.\n",
    "\n",
    "        Args:\n",
    "            url (str): the link string of webpage\n",
    "\n",
    "        Returns:\n",
    "            soup (obj): beautifulsoup object\n",
    "        \"\"\"\n",
    "        self.request = Request(self.url, headers={'User-Agent': 'Resistance is futile'})\n",
    "        self.response = urlopen(request)\n",
    "        return BeautifulSoup(self.response, \"html.parser\")\n",
    "    \n",
    "    \n",
    "    ### step3\n",
    "    def get_jobs_of_title(self, search_key): # function2-find info of each items of job in all pages\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            search_key (str): example: 'nintendo+switch+games'\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        head = 'https://www.walmart.com/'\n",
    "        #needed to be changed\n",
    "        num_pages = 2 #number of pages to scrape\n",
    "        page_gap_min = 3 #min sleep time between pages\n",
    "        page_gap_max = 5 #max sleep time between pages\n",
    "        job_per_page = 40 #number of jobs in one page\n",
    "        job_gap_min = 5 #min sleep time between jobs\n",
    "        job_gap_max = 15 #max sleep time between jobs\n",
    "\n",
    "        self.data_list = []\n",
    "\n",
    "        for i in range(num_pages): \n",
    "            #sleep between each call\n",
    "            gap = random.uniform(page_gap_min,page_gap_max) \n",
    "            time.sleep(gap)\n",
    "\n",
    "            #each page contains 50 jobs\n",
    "            tail = ''\n",
    "            if i == 0:\n",
    "                tail = 'search?q={0}'.format(search_key)\n",
    "            else:\n",
    "                tail = 'search?q={0}&page={1}&affinityOverride=default'.format(search_key,i+1)\n",
    "\n",
    "            #get link to joblist page\n",
    "            self.url = head+tail \n",
    "            print(self.url)\n",
    "            #get links to webpages of jobs on the joblist\n",
    "            self.job_page_links = get_job_links_from_page(self.url) # call fuction 3\n",
    "            #print(job_page_links)\n",
    "\n",
    "            for self.job_page_link in self.job_page_links:\n",
    "                gap = random.uniform(job_gap_min,job_gap_max) \n",
    "                time.sleep(gap)\n",
    "                data_new = get_info_from_job_page(self.job_page_link) # call function 4\n",
    "                #print(data_new)\n",
    "                print(json.dumps(data_new))\n",
    "                self.data_list.append(data_new)\n",
    "#         df = pd.DataFrame(data_list)\n",
    "#         df.to_csv('game_walmart.csv')\n",
    "\n",
    "    ### step1\n",
    "    def get_job_links_from_page(self, url): # function 3-find pages of jobs from main page\n",
    "        \"\"\"\n",
    "        This function gets the links of the jobs on the joblist page.\n",
    "\n",
    "        Args:\n",
    "            url (str): link to game page\n",
    "\n",
    "        Returns:\n",
    "            job_page_links (list): list of links to the webpages of the jobs\n",
    "        \"\"\"\n",
    "\n",
    "        self.job_page_links = []\n",
    "        soup = get_soup(self.url) # call function 1\n",
    "        #print('good soup')\n",
    "        #print(soup.prettify())\n",
    "        for item in soup.find_all(\"a\", href=True):\n",
    "            if 'Nintendo-Switch' in str(item) and 'ip' in str(item):#?athbdg=\n",
    "                link = item['href']\n",
    "                #print(link)\n",
    "                self.job_page_links.append('https://www.walmart.com'+link)\n",
    "        return self.job_page_links\n",
    "\n",
    "    ### step2\n",
    "    def get_info_from_job_page(self, url): # function4-get info of each item of job\n",
    "        \"\"\"\n",
    "        This function get all the useful info from the job webpage.\n",
    "\n",
    "        Args:\n",
    "            url (str): link to job webpage\n",
    "\n",
    "        Returns:\n",
    "            data (dict): dictionary with keywords: \n",
    "                         time_stamp, original_link, search_key, location, company, description\n",
    "        \"\"\"\n",
    "        soup = get_soup(self.url)\n",
    "        self.data = {}\n",
    "        #time_str = soup.find('div',class_='result-link-bar').find('span').getText()\n",
    "        #print('start:')\n",
    "        try:\n",
    "            #data[\"time_stamp\"] = get_timestamp(time_str).strftime(\"%d-%m-%Y %H:%M\") #call function5\n",
    "\n",
    "            self.data[\"Name\"] = soup.find('h1', class_=\"f3 b lh-copy dark-gray mt1 mb2\", itemprop=\"name\").getText()\n",
    "            self.data[\"Price\"] = soup.find('span',itemprop=\"price\").getText()\n",
    "            self.data[\"Rating\"] = soup.find('span', class_=\"f7 rating-number\").getText()\n",
    "            #print('data is:',data)\n",
    "    #         re_link = soup.find('a',class_='absolute w-100 h-100 z-1')['href']\n",
    "    #         print(re_link)\n",
    "    #         data[\"original_link\"] = get_original_link(re_link) #call function6\n",
    "        except:\n",
    "            pass\n",
    "        return self.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
